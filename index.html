<head>
    <title>Xin Jin</title>
    <meta name="author" content="Xin Jin">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:title" content="Xin Jin">
	<meta property="og:description" content="PhD student, Nankai University">
    <meta property="og:image" content="/assets/me.jpeg">
	<meta property="og:url" content="https://srameo.github.io/">
	<meta name="twitter:card" content="summary_large_image">
    <!-- <link rel="apple-touch-icon" href="/assets/paper_teaser/ucsd-logo.png"> -->
    <!-- <link rel="icon" type="image/png" href="/assets/paper_teaser/ucsd-logo.png"> -->
    <!-- <link rel="manifest" href="/assets/paper_teaser/site.webmanifest"> -->
    <link rel="stylesheet" href="css/style.css">
</head>

<!-- <div class="navbar">
    <a href="#about">About</a>
    <a href="#news">News</a>
    <a href="#publications">Publications</a>
    <a href="#experiences">Experiences</a>
    <a href="#contact">Contact</a>
</div> -->

<div class="header noselect" id="about">
    <div class="content row">
        <div class="header-profile-picture"></div>
        <div class="header-text">
            <div class="header-name">
                <h1>Xin Jin</h1>
            </div>
            <div class="header-subtitle">
                PhD student, Nankai University
            </div>
            <div class="header-links">
                <a class="btn" href="#contact">Email</a> /
                <a class="btn" href="https://scholar.google.com/citations?user=22M3mw8AAAAJ&hl=zh-CN">Google Scholar</a> /
                <a class="btn" href="https://github.com/Srameo">GitHub</a>
                <!-- <a class="btn" href="">CV</a> -->
            </div>
            <div>
                <p>
                    Xin Jin (靳鑫) is a PhD student at <a href="https://en.nankai.edu.cn/">Nankai University</a>, advised by Prof. <a href="https://mmcheng.net/">Ming-Ming Cheng</a>. 
                    His research interests include computer vision and deep learning, previously focusing on computational photography & 3D reconstruction.
                </p>
            </div>
        </div>
    </div>
</div>

<div class="content" style="padding-bottom: 64px;">
    <!-- News -->
    <div id="news">
        <h2 class="noselect">News</h2>
        <div class="news-container">
            <ul class="news-list noselect">
                <li class="news-item">2024/12 -- <a href="https://arxiv.org/abs/2407.03757">DiffRetouch</a> has been accepted by AAAI 2025!</li>
                <li class="news-item">2024/10 -- <a href="/projects/le3d/">LE3D</a> has been accepted by NeurIPS 2024! We are working on the release of the code. Please stay tuned! Hope to see you guys at Vancouver, Canada!</li>
                <li class="news-item">2024/06 -- We present <a href="/projects/le3d/">LE3D</a>, enabling real-time rendering for HDR view synthesis!</li>
                <li class="news-item">2024/01 -- The <a href="https://codalab.lisn.upsaclay.fr/competitions/17017">Few-shot RAW Image Denoising Track</a> in MIPI 2024 has started!</li>
                <li class="news-item">2023/12 -- A honor to co-organize the <a href="https://mipi-challenge.org/MIPI2024/">MIPI workshop</a> @ CVPR2024 with NTU S-Lab!</li>
                <li class="news-item">2023/12 -- We have released a <a href="/projects/led-extension/">extension version</a> of our <a href="/projects/led-iccv23/">LED</a>. Code is also released on <a href="https://github.com/Srameo/LED">Github</a>!</li>
                <li class="news-item">2023/07 -- The official code of <span class="italic">Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising</span> has been released on <a href="https://github.com/Srameo/LED">Github</a>!</li>
                <li class="news-item">2023/07 -- One paper, including <a href="/projects/led-iccv23/">LED</a>, got accepted by ICCV 2023.</li>
                <li class="news-item">2023/05 -- The official code of <span class="italic">DNF: Decouple and Feedback Network for Seeing in The Dark</span> has been released on <a href="https://github.com/Srameo/DNF">Github</a>!</li>
                <li class="news-item">2023/03 -- Excited to announce one paper accepted by CVPR 2023 was selected as <span class="bold">Highlight, 10% of accepted papers, 2.5% of submissions</span>!</li>
                <li class="news-item">2023/03 -- One paper got accepted by CVPR 2023.</li>
                <li class="news-item">2023/01 -- Our paper was awarded <span class="bold">oral presentation</span> qualification by AAAI.</li>
                <li class="news-item">2022/11 -- One paper got accepted by AAAI 2023.</li>
                <li class="news-item">2022/04 -- I have won the third place in RAW Image Blind De-noising as the team leader in Megcup 2022!</li>
                <li class="news-item">2022/04 -- Our team have won the third place in Night Photography Rendering Challenge, CVPRW 2022!</li>
                <li class="news-item">2022/03 -- One paper got accepted by ICPR 2022 and selected as <span class="bold">oral presentation</span>.</li>
            </ul>
        </div>
    </div>

    <!-- Publications -->
    <div id="publications">
        <h2 class="noselect">Publications <span style="font-size: 12px; color: #666;">(click to sort: 
            <a class="btn active" id="sort-author" onclick="sortPublications('author')">first author</a> / 
            <a class="btn" id="sort-date" onclick="sortPublications('date')">date</a>)</span></h2>
        <p>* Equal contribution. # Corresponding author. Representative papers are <span style="background-color: #fff8df">highlighted</span>.</p>
        <div class="publication row clearfix" data-author="Zhong-Yu Li" data-date="202412">
            <div class="row-media" style="height: 120px; background-image: url(/assets/paper_teaser/aodraw_teaser.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2411.15678">Towards RAW Object Detection in Diverse Conditions</a><br/>
                Zhong-Yu Li, <span class="bold">Xin Jin</span>, Boyuan Sun, Chun-Le Guo, Ming-Ming Cheng <br/>
                <span class="italic">arxiv</span>, 2024 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2411.15678">paper</a> / <a class="btn btn-dark" href="https://github.com/lzyhha/AODRaw">code</a> / <a class="btn btn-dark" href="bibtex/li2024towards.html">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix" data-author="Zheng-Peng Duan" data-date="202407">
            <div class="row-media" style="height: 100px; background-image: url(/assets/paper_teaser/diffretouch_teaser.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2407.03757">DiffRetouch: Using Diffusion to Retouch on the Shoulder of Experts</a><br/>
                Zheng-Peng Duan, Jiawei zhang, Zheng Lin, <span class="bold">Xin Jin</span>, Dongqing Zou, Chunle Guo, Chongyi Li <br/>
                <span class="italic"><a href="https://aaai.org/conference/aaai/aaai-25/">AAAI</a></span>, 2025 <br/>
                <a class="btn btn-red" href="https://arxiv.org/abs/2407.03757">paper</a> / <a class="btn btn-dark" href="bibtex/duan2024diffretouch.html">bibtex</a>
            </div>
        </div>
        <div class="highlight publication row clearfix" data-author="Xin Jin" data-date="202405">
            <div class="row-media" style="height: 120px; background-image: url(/assets/paper_teaser/le3d.gif); background-color: black;"></div>
            <div class="row-text">
                <a class="publication-title bold" href="/projects/le3d">Lighting Every Darkness with 3DGS: Fast Training and Real-Time Rendering for HDR View Synthesis</a><br/>
                <span class="bold">Xin Jin</span>*, Pengyi Jiao*, Zheng-Peng Duan, Xingchao Yang, Chongyi Li, Chun-Le Guo#, Bo Ren#.<br/>
                <span class="italic"><a href="https://nips.cc/Conferences/2024">NeurIPS</a></span>, 2024 
                <img style="position: relative; top:6px;" src="https://img.shields.io/github/stars/Srameo/LE3D?label=%F0%9F%8C%9F%20Star&color=blue">&nbsp;<img style="position: relative; top:6px;" src="https://img.shields.io/github/forks/Srameo/LE3D?label=%F0%9F%94%A7%20Fork&color=green"><br/>
                <a class="btn btn-dark" href="/projects/le3d">project</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2406.06216">paper</a> / <a class="btn btn-dark" href="https://github.com/Srameo/LE3D">code</a> / <a class="btn btn-dark" href="bibtex/jin2024le3d.html">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix" data-author="Xin Jin" data-date="202312">
            <div class="row-media" style="background-image: url(/projects/led-extension/assets/multiraw.jpg);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2308.03448v2">Make Explict Calibration Implicit: "Calibrate" Denoiser Instead of The Noise Model</a><br/>
                <span style="color:brown; font-size: smaller;">This is an extension of our <a href="/projects/led-iccv23/">LED, ICCV 2023</a>.</span><br/>
                <span class="bold">Xin Jin</span>, Jia-Wen Xiao, Ling-Hao Han, Chun-Le Guo#, Xialei Liu, Chong-Yi Li, Ming-Ming Cheng#.<br/>
                <span class="italic">arxiv</span>, 2023 
                <img style="position: relative; top:6px;" src="https://img.shields.io/github/stars/Srameo/LED?label=%F0%9F%8C%9F%20Star&color=blue">&nbsp;<img style="position: relative; top:6px;" src="https://img.shields.io/github/forks/Srameo/LED?label=%F0%9F%94%A7%20Fork&color=green"><br/>
                <a class="btn btn-dark" href="/projects/led-extension">project</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2308.03448v2">paper</a> / <a class="btn btn-dark" href="https://github.com/Srameo/LED">code</a> / <a class="btn btn-dark" href="bibtex/jin2023make.html">bibtex</a>
            </div>
        </div>
        <div class="highlight publication row clearfix" data-author="Xin Jin" data-date="202308">
            <div class="row-media" style="background-image: url(/assets/paper_teaser/led_teaser.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2308.03448v1">Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising</a><br/>
                <span class="bold">Xin Jin</span>*, Jia-Wen Xiao*, Ling-Hao Han, Chun-Le Guo#, Ruixun Zhang, Xialei Liu, Chong-Yi Li.<br/>
                <span class="italic"><a href="https://iccv2023.thecvf.com/">ICCV</a></span>, 2023 <img style="position: relative; top:6px;" src="https://img.shields.io/github/stars/Srameo/LED?label=%F0%9F%8C%9F%20Star&color=blue">&nbsp;<img style="position: relative; top:6px;" src="https://img.shields.io/github/forks/Srameo/LED?label=%F0%9F%94%A7%20Fork&color=green"><br/>
                <a class="btn btn-dark" href="/projects/led-iccv23">project</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2308.03448v1">paper</a> / <a class="btn btn-dark" href="https://github.com/Srameo/LED">code</a> / <a class="btn btn-dark" href="https://zhuanlan.zhihu.com/p/648242095">知乎</a> / <a class="btn btn-dark" href="bibtex/jin2023lighting.html">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix" data-author="Xin Jin" data-date="202305">
            <div class="row-media" style="height: 120px; background-image: url(/assets/paper_teaser/dnf_teaser.gif);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_DNF_Decouple_and_Feedback_Network_for_Seeing_in_the_Dark_CVPR_2023_paper.pdf">DNF: Decouple and Feedback Network for Seeing in the Dark</a><br/>
                <span class="bold">Xin Jin</span>*, Ling-Hao Han*, Zhen Li, Chun-Le Guo#,  Zhi Chai, Chong-Yi Li.<br/>
                <span class="italic"><a href="https://cvpr2023.thecvf.com/">CVPR</a></span>, 2023, (<span style="color: #f09228;">Highlight</span>) <img style="position: relative; top:6px;" src="https://img.shields.io/github/stars/Srameo/DNF?label=%F0%9F%8C%9F%20Star&color=blue">&nbsp;<img style="position: relative; top:6px;" src="https://img.shields.io/github/forks/Srameo/DNF?label=%F0%9F%94%A7%20Fork&color=green"><br/>
                <a class="btn btn-red" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_DNF_Decouple_and_Feedback_Network_for_Seeing_in_the_Dark_CVPR_2023_paper.pdf">paper</a> / <a class="btn btn-dark" href="https://github.com/Srameo/DNF">code</a> / <a class="btn btn-dark" href="bibtex/jin2023dnf.html">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix" data-author="Chun-Le Guo" data-date="202302">
            <div class="row-media" style="background-image: url(/assets/paper_teaser/uranker_teaser.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/abs/2208.06857">Underwater Ranker: Learn Which Is Better and How to Be Better</a><br/>
                Chun-Le Guo*, Rui-Qi Wu*, <span class="bold">Xin Jin</span>, Ling-Hao Han,  Zhi Chai, Wei-Dong Zhang, Chong-Yi Li#.<br/>
                <span class="italic"><a href="https://aaai-23.aaai.org/">AAAI</a></span>, 2023, (<span style="color: #f09228;">Oral</span>) <img style="position: relative; top:6px;" src="https://img.shields.io/github/stars/RQ-Wu/UnderwaterRanker?label=%F0%9F%8C%9F%20Star&color=blue">&nbsp;<img style="position: relative; top:6px;" src="https://img.shields.io/github/forks/RQ-Wu/UnderwaterRanker?label=%F0%9F%94%A7%20Fork&color=green"><br/>
                <a class="btn btn-dark" href="https://li-chongyi.github.io/URanker_files/">project</a> / <a class="btn btn-red" href="https://arxiv.org/abs/2208.06857">paper</a> / <a class="btn btn-dark" href="https://github.com/RQ-Wu/UnderwaterRanker">code</a> / <a class="btn btn-dark" href="https://pan.baidu.com/share/init?surl=K29p3gJWYa1ZM0vMHqI4uA">dataset (pwd: nuin)</a> / <a class="btn btn-dark" href="bibtex/guo2023underwater.html">bibtex</a>
            </div>
        </div>
        <div class="publication row clearfix" data-author="Jiacen Guo" data-date="202208">
            <div class="row-media" style="background-image: url(/assets/paper_teaser/icpr2023teaser.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://ieeexplore.ieee.org/abstract/document/9956275/">A Novel Low-light Image Enhancement Algorithm Based On Information Assistance</a><br/>
                Jiacen Guo, <span class="bold">Xin Jin</span>, Weilin Chen, Chao Wang#.<br/>
                <span class="italic"><a href="https://www.icpr2022.com/">ICPR</a></span>, 2022, (<span style="color: #f09228;">Oral</span>)<br/>
                <a class="btn btn-red" href="https://ieeexplore.ieee.org/abstract/document/9956275/">paper</a> / <a class="btn btn-dark" href="bibtex/guo2022novel.html">bibtex</a>
            </div>
        </div>
    </div>

    <!-- Experience -->
    <div id="experiences">
        <h2 class="noselect">Experience</h2>
        <div class="timeline noselect">
            <div class="timeline-item">
                <table>
                    <tr>
                        <td class="icon">
                            <a href="https://adobe.com/">
                            <img style="width: 125px;" src="https://www.adobe.com/home/assets/adobe_logo_red.svg" alt="Adobe"></a><br>
                            <span style="font-size: 13px;">2024/06 - 2024/11 <br> San Jose CA, USA</span>
                        </td>
                        <td class="description">
                            <h4><b>Research Scientist Intern</b></h4>
                            <p style="font-size: 13px;">Working with amazing researchers such as <a href="https://sniklaus.com/">Simon Niklaus</a>, <a href="https://likesum.github.io/">Zhihao Xia</a>, <a href="https://ztzhang.info/">Zhoutong Zhang</a> and <a href="https://people.csail.mit.edu/jiawen/">Jiawen Chen</a> (<a href="https://graphics.stanford.edu/~levoy/">Marc Levoy</a>'s team), where I was designing novel algorithms on practical denoising for in-the-wild videos and provide tech-support for <a href="https://www.adobe.com/products/premiere.html">Premiere Pro</a>.</p>
                        </td>
                    </tr>
                </table>
            </div>
            <div class="timeline-item">
                <table>
                    <tr>
                        <td class="icon">
                            <a href="https://mipi-challenge.org/MIPI2024/">
                            <img src="/assets/experience/mipi.png" alt="MIPI"></a><br>
                            <span style="font-size: 13px;">2023/12 - 2024/06<br> Seattle WA, USA</span>
                        </td>
                        <td class="description">
                            <h4><b>Joint Organizer</b></h4>
                            <p style="font-size: 13px;">Organized the MIPI workshop @ CVPR 2024 with <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>, <a href="https://www.jimmyren.com/">Jimmy S. Ren</a>, <a href="https://shangchenzhou.com/">Shangchen Zhou</a>, etc. I lead the <a href="https://codalab.lisn.upsaclay.fr/competitions/17017">Few-shot RAW Image Denoising Track</a>.</p>
                        </td>
                    </tr>
                </table>
            </div>
            <div class="timeline-item">
                <table>
                    <tr>
                        <td class="icon">
                            <a href="https://en.megvii.com/">
                            <img src="/assets/experience/megvii.png" alt="Megvii"></a><br>
                            <span style="font-size: 13px;">2022/05 - 2022/09 <span style="font-size: 8px;">(Engineer)</span><br> 2023/05 - 2024/06 <span style="font-size: 8px;">(Scientist)</span><br> Beijing, China</span>
                        </td>
                        <td class="description">
                            <h4><b>Research Intern</b></h4>
                            <p style="font-size: 13px;">Worked with <a href="https://bigeagle.me/about/">Yuzhi Wang</a> and Xingchao Yang, where I came up with the idea of <a href="/projects/led-iccv23/">LED</a> and worked on Burst Denoising and HDR view synthesis (<a href="/projects/le3d/">LE3D</a>).</p>
                        </td>
                    </tr>
                </table>
            </div>
        </div>
    </div>

    <!-- Awards -->
    <div>
        <h2 class="noselect">Competitions and Awards</h2>
        <ul class="noselect">
            <li style="margin-bottom: 8px;">Second Runner-up (Team Feedforward) in <a href="https://studio.brainpp.com/competition/5?tab=rank">RAW Image Blind Denoising, Megcup 2022</a>, serve as team leader.</li>
            <li style="margin-bottom: 8px;">Second Runner-up (Team Feedback) in <a href="https://nightimaging.org/final-leaderboard.html">Night Photography Rendering Challenge, CVPR Workshop 2022</a>.</li>
        </ul>
    </div>

    <!-- Education -->
    <div>
        <h2 class="noselect">Education</h2>
        <div  class="noselect">
            <span><strong>2022/09 - Present</strong>, I am a Ph.D student at <a href="https://cc.nankai.edu.cn/">College of Computer Science, Nankai University</a>, under the supervision of Prof. <a href="https://mmcheng.net/">Ming-Ming Cheng</a>.</span>
            <br/><br/>
            <span><strong>2018/09 - 2022/07</strong>, I was an undergraduate student at <a href="https://csen.nankai.edu.cn/">College of Software, Nankai University</a>.</span>
        </div>
    </div>

    <!-- Contact -->
    <div class="noselect">
        <a id="contact"></a>
        <h2>Contact</h2>
        You are very welcome to contact me regarding my research. I typically respond within a few days.<br/>
        I can be contacted directly at <span class="bold">xjin</span> [at] <span class="bold">mail.nankai.edu.cn</span>.
    </div>
</div>

<div id="footer-clusrmaps" style="width: 40%; position:relative; left:30%">
    <center>
        <div id="clustrmaps-widget" style="width:15%">
            <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=nlSICpnL-0hvum-TytLZ_nYEqZp0D4H5r2XiOv_YUsE"></script>
        </div>
    </center>
</div>

<div class="footer noselect">
    <div class="footer-content">
        &copy; 2022 Xin Jin. Acknowledgement to the template provided by <a style="color: white; text-decoration: underline;" href="https://nicklashansen.github.io">Nicklas Hansen</a>, but currently has been modified a lot by myself.
    </div>
</div>

<script>
function sortPublications(criteria) {
    const container = document.getElementById('publications');
    const publications = Array.from(container.getElementsByClassName('publication'));

    publications.sort((a, b) => {
        if (criteria === 'author') {
            if (a.getAttribute('data-author') === 'Xin Jin' && b.getAttribute('data-author') !== 'Xin Jin') {
                return -1;
            } else if (a.getAttribute('data-author') !== 'Xin Jin' && b.getAttribute('data-author') === 'Xin Jin') {
                return 1;
            } else {
                return b.getAttribute('data-date') - a.getAttribute('data-date');
            }
        } else if (criteria === 'date') {
            return b.getAttribute('data-date') - a.getAttribute('data-date');
        }
    });

    publications.forEach(pub => {
        container.appendChild(pub);
        // Add gray overlay to non-first-author publications
        if (criteria === 'author' && pub.getAttribute('data-author') !== 'Xin Jin') {
            pub.classList.add('gray-overlay');
        } else {
            pub.classList.remove('gray-overlay');
        }
    });

    // Toggle active class
    document.getElementById('sort-author').classList.toggle('active', criteria === 'author');
    document.getElementById('sort-date').classList.toggle('active', criteria === 'date');
}

document.addEventListener('DOMContentLoaded', function() {
    sortPublications('author');
});
</script>
